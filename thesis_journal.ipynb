{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V2ZL-T3roMnL"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from tensorboard_logger import configure\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import prep_data\n",
    "import train\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from models.transformer import Transformer\n",
    "from models.rnn import RNN, RNN5Day\n",
    "from models.transformer_encoder import TransformerEncoder\n",
    "from models.cnn import CNN\n",
    "from models.lstm import LSTM\n",
    "\n",
    "import mpu.io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "SyWr_EsBfJMk",
    "outputId": "f2d3c5f9-787e-4551-8dde-11001c9b62fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x207d71808f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuaXHMvoomFl",
    "outputId": "9e502495-1f8c-4b98-dd41-029a5a1d34db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    " dev = \"cuda:0\"\n",
    "else:\n",
    " dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def jsonify(json_data):\n",
    "    return json.loads(json.dumps(json_data, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "P-vGzMzHyLmb",
    "outputId": "8704a027-6771-4252-c8cf-aaeb1391ae6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params: 463489\n",
      "Epoch 000 | train loss 0.5227 | test_loss 0.5070 | wall_time 1.6912 | process_time 4.7812\n",
      "Epoch 001 | train loss 0.5222 | test_loss 0.5058 | wall_time 1.2425 | process_time 4.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train loss 0.5224 | test_loss 0.5056 | wall_time 1.2784 | process_time 4.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\User\\Desktop\\thesis-master\\prep_data.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params: 2316737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m MODELS \u001b[38;5;241m=\u001b[39m [LSTM(dropout\u001b[38;5;241m=\u001b[39mdropout), Transformer(dropout\u001b[38;5;241m=\u001b[39mdropout), CNN(dropout\u001b[38;5;241m=\u001b[39mdropout), RNN(dropout\u001b[38;5;241m=\u001b[39mdropout), ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m models \u001b[38;5;129;01min\u001b[39;00m MODELS:\n\u001b[1;32m---> 16\u001b[0m     model, best_model, loss, train_pred, test_pred, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dropout-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_seed-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\thesis-master\\train.py:123\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, seq_len, horizon, max_epoch, batch_size, start_date, end_date, loss, optimizer, lr, scale_method, device, nan)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;66;03m# Recording predictions\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         y_train_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(  \u001b[38;5;66;03m# y_train pred unnormed, y_pred is still normed\u001b[39;00m\n\u001b[0;32m    117\u001b[0m             (\n\u001b[0;32m    118\u001b[0m                 y_train_pred\u001b[38;5;241m.\u001b[39mcpu(), \u001b[38;5;66;03m# unnormed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    122\u001b[0m         )\n\u001b[1;32m--> 123\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m    127\u001b[0m         src\u001b[38;5;241m=\u001b[39mscaling\u001b[38;5;241m.\u001b[39mfit(train_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Returns\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m    128\u001b[0m         tgt\u001b[38;5;241m=\u001b[39mscaling\u001b[38;5;241m.\u001b[39mfit(train_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Returns\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m    129\u001b[0m         src_time\u001b[38;5;241m=\u001b[39mscaling\u001b[38;5;241m.\u001b[39mfit(train_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m    130\u001b[0m         tgt_time\u001b[38;5;241m=\u001b[39mscaling\u001b[38;5;241m.\u001b[39mfit(train_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    131\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = [512]\n",
    "DROPOUT = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "HORIZON = [1]\n",
    "PERIODS = {\n",
    "    \"train\": (\"2010-01-01\", \"2017-12-31\"),\n",
    "    \"test\": (\"2018-01-01\", \"2019-12-31\"),\n",
    "    \"gfc\":(\"2008-01-01\", \"2008-12-31\"),\n",
    "    \"covid\":(\"2020-01-01\", \"2022-12-31\")\n",
    " }\n",
    "\n",
    "for horizon in HORIZON:\n",
    "  for batch_size in BATCH_SIZE:\n",
    "    for dropout in DROPOUT:\n",
    "      MODELS = [LSTM(dropout=dropout), Transformer(dropout=dropout), CNN(dropout=dropout), RNN(dropout=dropout), ]\n",
    "      for models in MODELS:\n",
    "          model, best_model, loss, train_pred, test_pred, _ = train.train(\n",
    "              model=models,\n",
    "              seq_len=128,\n",
    "              horizon=horizon,\n",
    "              max_epoch=3,\n",
    "              batch_size=batch_size,\n",
    "              loss=nn.MSELoss(),\n",
    "              optimizer=optim.Adam,\n",
    "              lr=1e-4,\n",
    "              device=dev\n",
    "          )\n",
    "          config = f\"{model.model_type}_dropout-{dropout}_seed-{seed}\"\n",
    "          try:\n",
    "              os.mkdir(config)\n",
    "          except:\n",
    "              pass\n",
    "\n",
    "          os.chdir(config)\n",
    "          torch.save(model, f\"model_{config}.pth\")\n",
    "          torch.save(best_model, f\"best_model_{config}.pth\")\n",
    "          loss.to_csv(f\"metadata_{config}.csv\")\n",
    "          \n",
    "          if horizon == 1: \n",
    "              train_pred.to_csv(f\"train_{config}.csv\")\n",
    "              test_pred.to_csv(f\"test_{config}.csv\")\n",
    "          if horizon != 1:\n",
    "              mpu.io.write(f\"train_{config}.json\", jsonify(train_pred))\n",
    "              mpu.io.write(f\"test_{config}.json\", jsonify(test_pred))\n",
    "\n",
    "          for periods, range in PERIODS.items():\n",
    "            start_date, end_date = range\n",
    "            date_range = pd.date_range(start_date, end_date)\n",
    "            df, loss = train.test(\n",
    "              model=model,\n",
    "              seq_len=128,\n",
    "              horizon=horizon,\n",
    "              batch_size=0,\n",
    "              start_date=start_date,\n",
    "              end_date=end_date,\n",
    "              loss=nn.MSELoss(),\n",
    "              lr=1e-4,\n",
    "              scale_method=\"std\",\n",
    "              device=dev\n",
    "            )\n",
    "\n",
    "            if horizon == 1:\n",
    "              df = pd.DataFrame({\"y\": df[\"y\"], \"pred\": df[\"pred\"]},  index=date_range)\n",
    "\n",
    "            if horizon != 1:\n",
    "              df[\"index\"] = date_range\n",
    "              df[\"yy\"] = np.array([i[4] for i in df[\"y\"]])\n",
    "              df[\"5-day\"] = np.array([i[4] for i in df[\"pred\"]])\n",
    "              # print(df)\n",
    "              # print(df[\"yy\"].shape, df[\"pred\"].shape)\n",
    "\n",
    "              # print(df[\"5-day\"])\n",
    "\n",
    "              df = pd.DataFrame({\"y\" : df[\"yy\"], \"pred\": df[\"5-day\"]}, index=df[\"index\"])\n",
    "\n",
    "          os.chdir(\"..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
