{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6OVBygNG_4s"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "brLVmgNT0izE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from tensorboard_logger import configure\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.auto import AutoVanillaTransformer, AutoRNN, AutoAutoformer\n",
    "from neuralforecast.models import VanillaTransformer, RNN, Autoformer\n",
    "from neuralforecast.losses.pytorch import MAE, MSE, MAPE, RMSE\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dCs51ZS0uW3",
    "outputId": "07ce2eca-4f71-4093-824f-2802fceb9025",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    " dev = \"cuda:0\"\n",
    "else:\n",
    " dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpkrg14PHDLs"
   },
   "source": [
    "# Load data from `yfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bhgL3OoU2kdW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXCHANGES = [\"PSEI.PS\"]\n",
    "\n",
    "START_DATE = \"2010-1-1\"\n",
    "END_DATE = \"2019-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "lIsPFPCb0vPu",
    "outputId": "d9c01759-7029-4066-e494-728070bb5ddc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "2019-12-27  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-28  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-29  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-30  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-31  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "\n",
       "              Volume  \n",
       "2019-12-27  177800.0  \n",
       "2019-12-28  177800.0  \n",
       "2019-12-29  177800.0  \n",
       "2019-12-30  177800.0  \n",
       "2019-12-31  177800.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.date_range(START_DATE, END_DATE)\n",
    "\n",
    "raw_data = yf.download(EXCHANGES, START_DATE, END_DATE)\n",
    "raw_data = raw_data.reindex(idx)\n",
    "raw_data.fillna(method=\"ffill\", inplace=True)\n",
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VD1EDni9gace"
   },
   "source": [
    "# Prepare dataframe for `neuralforecast`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QAkdJzmngZHr",
    "outputId": "e4f6dd91-eb63-4388-9801-ff87f1e489e2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>3012.550049</td>\n",
       "      <td>3034.070068</td>\n",
       "      <td>3011.489990</td>\n",
       "      <td>3028.459961</td>\n",
       "      <td>3027.681396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>3035.290039</td>\n",
       "      <td>3041.270020</td>\n",
       "      <td>3029.510010</td>\n",
       "      <td>3039.929932</td>\n",
       "      <td>3039.148438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>3043.090088</td>\n",
       "      <td>3077.780029</td>\n",
       "      <td>3041.860107</td>\n",
       "      <td>3077.780029</td>\n",
       "      <td>3076.988770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>3077.489990</td>\n",
       "      <td>3077.489990</td>\n",
       "      <td>3062.550049</td>\n",
       "      <td>3077.179932</td>\n",
       "      <td>3076.388916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-09</th>\n",
       "      <td>3077.489990</td>\n",
       "      <td>3077.489990</td>\n",
       "      <td>3062.550049</td>\n",
       "      <td>3077.179932</td>\n",
       "      <td>3076.388916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>-0.003451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>7848.390137</td>\n",
       "      <td>7891.990234</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7815.259766</td>\n",
       "      <td>7813.250488</td>\n",
       "      <td>177800.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3648 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "2010-01-05  3012.550049  3034.070068  3011.489990  3028.459961  3027.681396   \n",
       "2010-01-06  3035.290039  3041.270020  3029.510010  3039.929932  3039.148438   \n",
       "2010-01-07  3043.090088  3077.780029  3041.860107  3077.780029  3076.988770   \n",
       "2010-01-08  3077.489990  3077.489990  3062.550049  3077.179932  3076.388916   \n",
       "2010-01-09  3077.489990  3077.489990  3062.550049  3077.179932  3076.388916   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2019-12-27  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-28  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-29  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-30  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "2019-12-31  7848.390137  7891.990234  7815.259766  7815.259766  7813.250488   \n",
       "\n",
       "              Volume  Log Returns  \n",
       "2010-01-05       0.0     0.007773  \n",
       "2010-01-06       0.0     0.003780  \n",
       "2010-01-07       0.0     0.012374  \n",
       "2010-01-08       0.0    -0.000195  \n",
       "2010-01-09       0.0     0.000000  \n",
       "...              ...          ...  \n",
       "2019-12-27  177800.0    -0.003451  \n",
       "2019-12-28  177800.0     0.000000  \n",
       "2019-12-29  177800.0     0.000000  \n",
       "2019-12-30  177800.0     0.000000  \n",
       "2019-12-31  177800.0     0.000000  \n",
       "\n",
       "[3648 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"Log Returns\"] = np.log(raw_data[\"Adj Close\"]/raw_data[\"Adj Close\"].shift(1))\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyfLfSczigHS"
   },
   "source": [
    "## Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cHtweS4Ug3jQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "for feature in raw_data.columns:\n",
    "  feature_df = pd.DataFrame(index=raw_data.index)\n",
    "  feature_df[\"ds\"] = raw_data.index\n",
    "  feature_df[\"y\"] = raw_data[feature]\n",
    "  feature_df[\"unique_id\"] = f\"PSEI.PS {feature}\"\n",
    "  df_lst.append(feature_df)\n",
    "\n",
    "# Log returns df is df_lst[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "fKVSaKsF310Z",
    "outputId": "a162a499-40a9-42c4-fd17-974bca3bd97a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27b43b17e0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_lst[-1][\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Lq4oJbZ6O90l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = m.ceil(.2*len(raw_data.index))\n",
    "test_size = m.ceil(.2*len(raw_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZbGE5CbKzJai",
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_LAYERS = [1,2,4]\n",
    "HORIZON = [1,5]\n",
    "LEARNING_RATE = [1e-4]\n",
    "SEQ_LENGTH =  [64,128]\n",
    "EPOCH = [1000]\n",
    "N_HEAD = [2,4]    # Number of attention heads\n",
    "D_MODEL =  [64,128]  # Hidden dimension of the model\n",
    "BATCH_SIZE = [16,32,64]\n",
    "DROPOUT = [0.1*i for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "MYXYAea3k14q",
    "outputId": "953a9811-0dda-4a01-e8db-5e8bdfcf705b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "36cNAv38jcM9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_rnn = {\n",
    "    \"input_size\": tune.choice(SEQ_LENGTH),\n",
    "    \"encoder_dropout\": tune.choice(DROPOUT),\n",
    "    \"learning_rate\": tune.choice(LEARNING_RATE),\n",
    "    \"max_steps\": tune.choice(EPOCH),\n",
    "    \"batch_size\": tune.choice(BATCH_SIZE),\n",
    "    \"alias\": \"RNN\"\n",
    "}\n",
    "\n",
    "config_transformers = {\n",
    "    \"input_size\": tune.choice(SEQ_LENGTH),\n",
    "    \"encoder_layers\": tune.choice(N_LAYERS),\n",
    "    \"decoder_layers\": tune.choice(N_LAYERS),\n",
    "    \"dropout\": tune.choice(DROPOUT),\n",
    "    \"learning_rate\": tune.choice(LEARNING_RATE),\n",
    "    \"max_steps\": tune.choice(EPOCH),\n",
    "    \"batch_size\": tune.choice(BATCH_SIZE),\n",
    "    \"alias\": \"Transformer\"\n",
    "}\n",
    "\n",
    "config_autoformer = {\n",
    "    \"input_size\": tune.choice(SEQ_LENGTH),\n",
    "    \"encoder_layers\": tune.choice(N_LAYERS),\n",
    "    \"decoder_layers\": tune.choice(N_LAYERS),\n",
    "    \"dropout\": tune.choice(DROPOUT),\n",
    "    \"learning_rate\": tune.choice(LEARNING_RATE),\n",
    "    \"max_steps\": tune.choice(EPOCH),\n",
    "    \"batch_size\": tune.choice(BATCH_SIZE),\n",
    "    \"alias\": \"Autoformer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456,
     "referenced_widgets": [
      "b11e473f57d044b48760707574611afb",
      "5e2dd7aac6d842dcb987d5417b1b5487",
      "c388f95c4c4d4b9ab5cdf1da5cff808a",
      "659fef089ee247e599e6fcdde8eddfaf",
      "cd47a1711d0047e8a406b464b3a4ad8f",
      "ac2eb6bedd8f4bff807a58175bad5e0b",
      "f10cd5d8f6ca4266bf08eb05b3c5940a",
      "4aa6091d14fe48af8b090ee16666b74a",
      "bac194cb12924ecb85d52b82c27b315b",
      "33a2d42468714c0998d3b0a63dec123a",
      "b64305d4a1d84703b856327b96f83084"
     ]
    },
    "id": "CdIbwv0291Sh",
    "outputId": "78bb4671-9ddb-4bb2-9eb8-c154faa6f8b1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=17572)\u001b[0m Seed set to 1\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m WARNING:root:XRT configuration not detected. Defaulting to preview PJRT runtime. To silence this warning and continue using PJRT, explicitly set PJRT_DEVICE to a supported device or configure XRT. To disable default device selection, set PJRT_SELECT_DEFAULT_DEVICE=0\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m WARNING:root:For more information about the status of PJRT, see https://github.com/pytorch/xla/blob/master/docs/pjrt.md\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m WARNING:root:Defaulting to PJRT_DEVICE=CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]        \n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]        \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]        \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.79it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]       \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]        \n",
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]        \n",
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.72it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]        \n",
      "Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952]        \n",
      "Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952]\n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060]\n",
      "Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]        \n",
      "Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.27it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.26it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]        \n",
      "Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.110]\n",
      "Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.83it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.24it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.020]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.31it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]       \n",
      "Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]        \n",
      "Epoch 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.853]        \n",
      "Epoch 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.34it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.853]\n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.853]        \n",
      "Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.853]\n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.853]        \n",
      "Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.853]\n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]        \n",
      "Epoch 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.853]        \n",
      "Epoch 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.853]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.853]        \n",
      "Epoch 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.853]\n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]        \n",
      "Epoch 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.853]        \n",
      "Epoch 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.853]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]        \n",
      "Epoch 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.853]        \n",
      "Epoch 129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.853]\n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.853]        \n",
      "Epoch 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.853]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.853]        \n",
      "Epoch 132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.853]\n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.853]        \n",
      "Epoch 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.853]\n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.853]        \n",
      "Epoch 136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.853]\n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]        \n",
      "Epoch 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]        \n",
      "Epoch 140: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]        \n",
      "Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]\n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]        \n",
      "Epoch 142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]\n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.853]        \n",
      "Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.853]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=0.853]        \n",
      "Epoch 145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=0.853]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.853]        \n",
      "Epoch 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.853]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.853]        \n",
      "Epoch 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.853]\n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.853]        \n",
      "Epoch 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.853]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.853]        \n",
      "Epoch 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.853]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.853]        \n",
      "Epoch 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.853]\n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.853]        \n",
      "Epoch 159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.853]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.853]        \n",
      "Epoch 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.853]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]        \n",
      "Epoch 163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.853]        \n",
      "Epoch 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.853]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]        \n",
      "Epoch 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]\n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.853]        \n",
      "Epoch 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.853]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.853]        \n",
      "Epoch 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.853]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]        \n",
      "Epoch 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]        \n",
      "Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.853]        \n",
      "Epoch 174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.853]\n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]        \n",
      "Epoch 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]\n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]        \n",
      "Epoch 177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]\n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.853]        \n",
      "Epoch 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.853]\n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.853]        \n",
      "Epoch 179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.853]\n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.853]        \n",
      "Epoch 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.853]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]        \n",
      "Epoch 184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]\n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]        \n",
      "Epoch 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.853]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.853]        \n",
      "Epoch 190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.853]\n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.853]        \n",
      "Epoch 192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.853]\n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.853]        \n",
      "Epoch 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.853]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.853]        \n",
      "Epoch 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.853]\n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]        \n",
      "Epoch 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.21it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.852]        \n",
      "Epoch 203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.852]\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.852]        \n",
      "Epoch 204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.852]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]        \n",
      "Epoch 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.852]        \n",
      "Epoch 206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.852]\n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]        \n",
      "Epoch 207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]        \n",
      "Epoch 208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]\n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]        \n",
      "Epoch 209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]        \n",
      "Epoch 210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]        \n",
      "Epoch 211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]\n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]        \n",
      "Epoch 213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]\n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]        \n",
      "Epoch 214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]\n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]        \n",
      "Epoch 215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]\n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.852]        \n",
      "Epoch 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.852]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]        \n",
      "Epoch 217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]        \n",
      "Epoch 218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]\n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]        \n",
      "Epoch 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.25it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]\n",
      "Epoch 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]\n",
      "Epoch 221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.852]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]        \n",
      "Epoch 222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.852]        \n",
      "Epoch 223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.852]\n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]        \n",
      "Epoch 224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.852]        \n",
      "Epoch 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.852]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]        \n",
      "Epoch 226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.852]        \n",
      "Epoch 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.852]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.852]        \n",
      "Epoch 230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.852]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]        \n",
      "Epoch 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]        \n",
      "Epoch 232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]\n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]        \n",
      "Epoch 233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]        \n",
      "Epoch 234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.852]        \n",
      "Epoch 235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.852]\n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]        \n",
      "Epoch 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.852]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.852]        \n",
      "Epoch 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.852]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]        \n",
      "Epoch 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]        \n",
      "Epoch 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.852]        \n",
      "Epoch 242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.852]\n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]        \n",
      "Epoch 243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]\n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.852]        \n",
      "Epoch 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.852]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]        \n",
      "Epoch 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]        \n",
      "Epoch 246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]        \n",
      "Epoch 248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.31it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.852]        \n",
      "Epoch 250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.852]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.852]        \n",
      "Epoch 251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.852]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]        \n",
      "Epoch 252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.852]\n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]        \n",
      "Epoch 253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]        \n",
      "Epoch 254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]\n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.852]        \n",
      "Epoch 255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.852]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.852]        \n",
      "Epoch 256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.852]\n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]        \n",
      "Epoch 257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]\n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.852]        \n",
      "Epoch 258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.852]\n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]        \n",
      "Epoch 259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]        \n",
      "Epoch 260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.852]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.852]        \n",
      "Epoch 261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.852]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]        \n",
      "Epoch 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.852]        \n",
      "Epoch 263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.852]\n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]        \n",
      "Epoch 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]        \n",
      "Epoch 265: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]\n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.852]        \n",
      "Epoch 266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.852]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]        \n",
      "Epoch 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.852]        \n",
      "Epoch 268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.852]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]        \n",
      "Epoch 269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]\n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]        \n",
      "Epoch 270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.852]        \n",
      "Epoch 271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.852]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]        \n",
      "Epoch 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.852]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]        \n",
      "Epoch 274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]\n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.852]        \n",
      "Epoch 276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.852]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]        \n",
      "Epoch 277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.852]\n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]        \n",
      "Epoch 278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.852]\n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.852]        \n",
      "Epoch 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.852]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.852]        \n",
      "Epoch 280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.852]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.852]        \n",
      "Epoch 281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.852]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.852]        \n",
      "Epoch 282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.852]\n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]        \n",
      "Epoch 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.852]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]        \n",
      "Epoch 284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.852]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]        \n",
      "Epoch 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.852]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]        \n",
      "Epoch 286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.852]        \n",
      "Epoch 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.852]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.852]        \n",
      "Epoch 288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.852]\n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]        \n",
      "Epoch 289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]        \n",
      "Epoch 290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.852]\n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]        \n",
      "Epoch 291: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.852]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.852]        \n",
      "Epoch 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.852]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]        \n",
      "Epoch 293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.852]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.852]        \n",
      "Epoch 294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.852]\n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]        \n",
      "Epoch 295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.852]\n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.852]        \n",
      "Epoch 296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.852]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]        \n",
      "Epoch 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.060, valid_loss=0.852]\n",
      "Epoch 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.852]\n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.852]        \n",
      "Epoch 298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.852]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.852]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.852]\n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.945, valid_loss=0.852]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.853]        \n",
      "Epoch 300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.853]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]        \n",
      "Epoch 301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.853]        \n",
      "Epoch 302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.853]\n",
      "Epoch 302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]        \n",
      "Epoch 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]        \n",
      "Epoch 307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]\n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.853]        \n",
      "Epoch 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.853]\n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.853]        \n",
      "Epoch 313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.853]\n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.853]        \n",
      "Epoch 316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.853]\n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]        \n",
      "Epoch 317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.853]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 319: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.853]        \n",
      "Epoch 321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.853]\n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.853]        \n",
      "Epoch 322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.853]\n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]        \n",
      "Epoch 323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.853]        \n",
      "Epoch 324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.853]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]        \n",
      "Epoch 325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.853]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.853]        \n",
      "Epoch 327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.28it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.853]\n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.31it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.853]        \n",
      "Epoch 334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.853]\n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.853]        \n",
      "Epoch 336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.853]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.853]        \n",
      "Epoch 340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.853]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]        \n",
      "Epoch 343: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.853]\n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]        \n",
      "Epoch 344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]\n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.853]        \n",
      "Epoch 346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.853]\n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.853]        \n",
      "Epoch 347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.853]\n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.853]        \n",
      "Epoch 348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.853]\n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]        \n",
      "Epoch 350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.853]        \n",
      "Epoch 357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.853]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]        \n",
      "Epoch 358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.853]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]        \n",
      "Epoch 359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]\n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 360: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.853]        \n",
      "Epoch 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.853]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.853]        \n",
      "Epoch 362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.853]\n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]        \n",
      "Epoch 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.23it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.853]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.853]        \n",
      "Epoch 364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.853]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]        \n",
      "Epoch 365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.853]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]        \n",
      "Epoch 366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.853]\n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]        \n",
      "Epoch 372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.853]\n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.853]        \n",
      "Epoch 373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.853]\n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.853]        \n",
      "Epoch 377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.853]\n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.853]        \n",
      "Epoch 378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.853]\n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.853]        \n",
      "Epoch 380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.853]\n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.853]        \n",
      "Epoch 381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.853]\n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.853]        \n",
      "Epoch 382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.853]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]        \n",
      "Epoch 383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.853]\n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]        \n",
      "Epoch 384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.853]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]        \n",
      "Epoch 385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]        \n",
      "Epoch 386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.853]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.853]        \n",
      "Epoch 387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.853]\n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]        \n",
      "Epoch 388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.853]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]        \n",
      "Epoch 389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.853]\n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.853]        \n",
      "Epoch 391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.853]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]        \n",
      "Epoch 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.853]\n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]        \n",
      "Epoch 395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.853]\n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]        \n",
      "Epoch 396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.853]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]        \n",
      "Epoch 397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.853]\n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.853]        \n",
      "Epoch 398: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.853]\n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.853]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.32it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]        \n",
      "Epoch 400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]        \n",
      "Epoch 401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.866]        \n",
      "Epoch 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.866]\n",
      "Epoch 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.866]\n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.866]        \n",
      "Epoch 403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.866]\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.866]        \n",
      "Epoch 404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.866]\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.866]        \n",
      "Epoch 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.866]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]        \n",
      "Epoch 407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]\n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.866]        \n",
      "Epoch 408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.866]\n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]        \n",
      "Epoch 409: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]\n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]        \n",
      "Epoch 410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]\n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]        \n",
      "Epoch 411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.866]        \n",
      "Epoch 412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.866]\n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.866]        \n",
      "Epoch 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.866]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.866]        \n",
      "Epoch 414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.866]\n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]        \n",
      "Epoch 416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]\n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=0.866]        \n",
      "Epoch 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=0.866]\n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.866]        \n",
      "Epoch 418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.866]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]        \n",
      "Epoch 419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]\n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.866]        \n",
      "Epoch 420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.866]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.866]        \n",
      "Epoch 421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.866]\n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]        \n",
      "Epoch 424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.866]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.866]        \n",
      "Epoch 426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.866]\n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.866]        \n",
      "Epoch 427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.866]\n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]        \n",
      "Epoch 428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]\n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.866]        \n",
      "Epoch 429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.866]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.866]        \n",
      "Epoch 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.866]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.866]        \n",
      "Epoch 433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.866]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]        \n",
      "Epoch 434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]\n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]        \n",
      "Epoch 435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]\n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.866]        \n",
      "Epoch 436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.866]\n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]        \n",
      "Epoch 437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.866]        \n",
      "Epoch 438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.866]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.866]        \n",
      "Epoch 440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.866]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.866]        \n",
      "Epoch 441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.866]\n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]        \n",
      "Epoch 442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.31it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.866]        \n",
      "Epoch 444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.866]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.866]        \n",
      "Epoch 445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.866]\n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.866]        \n",
      "Epoch 446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.866]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.866]        \n",
      "Epoch 447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.866]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.866]        \n",
      "Epoch 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.866]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]        \n",
      "Epoch 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.866]        \n",
      "Epoch 452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.866]\n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]        \n",
      "Epoch 453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]\n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.866]        \n",
      "Epoch 454: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.866]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.866]        \n",
      "Epoch 455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.866]\n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.866]        \n",
      "Epoch 456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.866]\n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.866]        \n",
      "Epoch 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.866]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]        \n",
      "Epoch 458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.866]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=0.866]        \n",
      "Epoch 459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=0.866]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]        \n",
      "Epoch 460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]        \n",
      "Epoch 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.866]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.866]        \n",
      "Epoch 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.866]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.866]        \n",
      "Epoch 463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.866]\n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]        \n",
      "Epoch 464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.866]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.866]        \n",
      "Epoch 466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.866]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]        \n",
      "Epoch 467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]\n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.866]        \n",
      "Epoch 468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.866]\n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.866]        \n",
      "Epoch 470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.866]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.866]        \n",
      "Epoch 471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.866]\n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.866]        \n",
      "Epoch 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.866]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.866]        \n",
      "Epoch 473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.866]\n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.866]        \n",
      "Epoch 474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.866]\n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.866]        \n",
      "Epoch 475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.866]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.866]        \n",
      "Epoch 476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.866]\n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.866]        \n",
      "Epoch 477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.866]\n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.866]        \n",
      "Epoch 478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.866]\n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]        \n",
      "Epoch 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.866]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.866]        \n",
      "Epoch 483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.866]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]        \n",
      "Epoch 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.866]\n",
      "Epoch 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.866]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.866]        \n",
      "Epoch 485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.28it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.866]\n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]        \n",
      "Epoch 487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]        \n",
      "Epoch 488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.866]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.866]        \n",
      "Epoch 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.866]\n",
      "Epoch 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.866]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.866]        \n",
      "Epoch 490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.866]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.866]        \n",
      "Epoch 491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.866]\n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]        \n",
      "Epoch 492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.866]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.866]        \n",
      "Epoch 493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.866]\n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]        \n",
      "Epoch 494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.866]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.866]        \n",
      "Epoch 496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.866]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]        \n",
      "Epoch 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.866]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]        \n",
      "Epoch 498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.866]\n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.010, valid_loss=0.866]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.55it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.892]        \n",
      "Epoch 500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.892]\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.892]        \n",
      "Epoch 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.892]\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.892]        \n",
      "Epoch 503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.892]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]        \n",
      "Epoch 504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]\n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]        \n",
      "Epoch 505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.892]        \n",
      "Epoch 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.892]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]        \n",
      "Epoch 507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]        \n",
      "Epoch 508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]\n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.892]        \n",
      "Epoch 509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.892]\n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.892]        \n",
      "Epoch 510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.892]\n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.892]        \n",
      "Epoch 511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.892]\n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.892]        \n",
      "Epoch 512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.892]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.892]        \n",
      "Epoch 513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.892]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.892]        \n",
      "Epoch 514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.892]\n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]        \n",
      "Epoch 515: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]\n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.892]        \n",
      "Epoch 516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.892]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.892]        \n",
      "Epoch 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.892]\n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.892]        \n",
      "Epoch 519: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.892]\n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]        \n",
      "Epoch 520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.892]        \n",
      "Epoch 521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.892]\n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.892]        \n",
      "Epoch 523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.892]\n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]        \n",
      "Epoch 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.892]        \n",
      "Epoch 525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.892]\n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.892]        \n",
      "Epoch 526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.892]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.892]        \n",
      "Epoch 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.892]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.892]        \n",
      "Epoch 528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.892]\n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.892]        \n",
      "Epoch 529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.892]\n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]        \n",
      "Epoch 530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]\n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.892]        \n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.892]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.892]        \n",
      "Epoch 532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.892]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.892]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.892]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]        \n",
      "Epoch 534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.892]        \n",
      "Epoch 535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.892]\n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.892]        \n",
      "Epoch 536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.892]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]        \n",
      "Epoch 537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]\n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]        \n",
      "Epoch 538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.892]        \n",
      "Epoch 539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.892]\n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]        \n",
      "Epoch 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]\n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.892]        \n",
      "Epoch 541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.892]\n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]        \n",
      "Epoch 542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]\n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.892]        \n",
      "Epoch 543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.892]\n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.892]        \n",
      "Epoch 544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.892]\n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.892]        \n",
      "Epoch 545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.892]\n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]        \n",
      "Epoch 546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]\n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.892]        \n",
      "Epoch 548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.892]\n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.892]        \n",
      "Epoch 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.892]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.892]        \n",
      "Epoch 550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.892]\n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.892]        \n",
      "Epoch 551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.892]\n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.892]        \n",
      "Epoch 552: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.892]\n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]        \n",
      "Epoch 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.892]        \n",
      "Epoch 554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.892]\n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]        \n",
      "Epoch 555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]\n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.892]        \n",
      "Epoch 556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.18it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.892]\n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.892]        \n",
      "Epoch 557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.892]\n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.892]        \n",
      "Epoch 558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.22it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.892]\n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.892]        \n",
      "Epoch 560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.892]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.892]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.892]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]        \n",
      "Epoch 562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]\n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.892]        \n",
      "Epoch 563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.892]\n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]        \n",
      "Epoch 564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.892]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.892]        \n",
      "Epoch 565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.892]\n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]        \n",
      "Epoch 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.892]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.892]        \n",
      "Epoch 567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.892]\n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.892]        \n",
      "Epoch 568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.892]\n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]        \n",
      "Epoch 569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]\n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.892]        \n",
      "Epoch 570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.892]\n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 573: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]        \n",
      "Epoch 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]        \n",
      "Epoch 575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]\n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.892]        \n",
      "Epoch 576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.892]\n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]        \n",
      "Epoch 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.892]\n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]        \n",
      "Epoch 578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]\n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.892]        \n",
      "Epoch 579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.892]\n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]        \n",
      "Epoch 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.892]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.892]        \n",
      "Epoch 581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.892]\n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.892]        \n",
      "Epoch 582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.892]\n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]        \n",
      "Epoch 583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.892]\n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.892]        \n",
      "Epoch 584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.892]\n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.892]        \n",
      "Epoch 585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.892]\n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.892]        \n",
      "Epoch 586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.892]\n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]        \n",
      "Epoch 587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.892]\n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]        \n",
      "Epoch 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.892]\n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.892]        \n",
      "Epoch 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.892]\n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.892]        \n",
      "Epoch 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.892]\n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.892]        \n",
      "Epoch 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.892]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]        \n",
      "Epoch 595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.892]\n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]        \n",
      "Epoch 596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.892]\n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]        \n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.892]\n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.892]        \n",
      "Epoch 598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.892]\n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.892]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.892]\n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.878, valid_loss=0.892]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.47it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.906]        \n",
      "Epoch 600: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.906]\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.906]        \n",
      "Epoch 601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.906]\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.906]        \n",
      "Epoch 602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.906]\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.906]        \n",
      "Epoch 603: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.906]\n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.906]        \n",
      "Epoch 604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.906]\n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.906]        \n",
      "Epoch 605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.906]\n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]        \n",
      "Epoch 606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]\n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.906]        \n",
      "Epoch 607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.906]\n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]        \n",
      "Epoch 608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]\n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.906]        \n",
      "Epoch 609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.906]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.906]        \n",
      "Epoch 610: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.906]\n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.906]        \n",
      "Epoch 611: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.906]\n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.906]        \n",
      "Epoch 612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.906]\n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.906]        \n",
      "Epoch 613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.906]\n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.906]        \n",
      "Epoch 614: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.906]\n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.906]        \n",
      "Epoch 615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.906]\n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.906]        \n",
      "Epoch 616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.906]\n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.906]        \n",
      "Epoch 617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.906]\n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.906]        \n",
      "Epoch 618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.906]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.906]        \n",
      "Epoch 619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.906]\n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.906]        \n",
      "Epoch 620: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.906]\n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.906]        \n",
      "Epoch 621: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.906]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.906]        \n",
      "Epoch 622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.906]\n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.906]        \n",
      "Epoch 623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.906]\n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.906]        \n",
      "Epoch 624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.906]\n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.906]        \n",
      "Epoch 625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.906]\n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=0.843, valid_loss=0.906]        \n",
      "Epoch 626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=0.843, valid_loss=0.906]\n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.906]        \n",
      "Epoch 627: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.906]\n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.906]        \n",
      "Epoch 628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.906]\n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.906]        \n",
      "Epoch 629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.906]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.906]        \n",
      "Epoch 630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.906]\n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]        \n",
      "Epoch 631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]\n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.906]        \n",
      "Epoch 632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.906]\n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]        \n",
      "Epoch 633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]\n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.906]        \n",
      "Epoch 634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.906]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.906]        \n",
      "Epoch 635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.906]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.906]        \n",
      "Epoch 636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.906]\n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.906]        \n",
      "Epoch 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.906]\n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.906]        \n",
      "Epoch 638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.906]\n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.906]        \n",
      "Epoch 639: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.906]\n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.906]        \n",
      "Epoch 640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.906]\n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]        \n",
      "Epoch 641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.906]        \n",
      "Epoch 642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.906]\n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=0.906]        \n",
      "Epoch 643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=0.906]\n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.906]        \n",
      "Epoch 644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.906]\n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.906]        \n",
      "Epoch 645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.906]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.906]        \n",
      "Epoch 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.906]\n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.906]        \n",
      "Epoch 647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.906]\n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]        \n",
      "Epoch 648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]\n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.906]        \n",
      "Epoch 649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.906]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]        \n",
      "Epoch 650: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.906]\n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]        \n",
      "Epoch 651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]\n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.906]        \n",
      "Epoch 652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.906]\n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.906]        \n",
      "Epoch 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.906]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=0.906]        \n",
      "Epoch 654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=0.906]\n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.906]        \n",
      "Epoch 655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.906]\n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.906]        \n",
      "Epoch 656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.906]\n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]        \n",
      "Epoch 657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.906]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.906]        \n",
      "Epoch 658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.906]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.906]        \n",
      "Epoch 659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.906]\n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.906]        \n",
      "Epoch 660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.906]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.906]        \n",
      "Epoch 661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.906]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.906]        \n",
      "Epoch 662: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.906]\n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.906]        \n",
      "Epoch 663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.906]\n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.906]        \n",
      "Epoch 664: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.906]\n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]        \n",
      "Epoch 665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.906]\n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.906]        \n",
      "Epoch 666: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.906]\n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.906]        \n",
      "Epoch 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.906]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.906]        \n",
      "Epoch 668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.906]\n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.906]        \n",
      "Epoch 669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.906]\n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.906]        \n",
      "Epoch 670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.906]\n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]        \n",
      "Epoch 671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.906]        \n",
      "Epoch 672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.906]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]        \n",
      "Epoch 673: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]\n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.906]        \n",
      "Epoch 674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.906]\n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.906]        \n",
      "Epoch 675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.906]\n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.906]        \n",
      "Epoch 676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.906]\n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]        \n",
      "Epoch 677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.906]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.906]        \n",
      "Epoch 678: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.906]\n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.906]        \n",
      "Epoch 679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.906]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.906]        \n",
      "Epoch 680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.906]\n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.906]        \n",
      "Epoch 681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.906]\n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.906]        \n",
      "Epoch 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.906]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.906]        \n",
      "Epoch 683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.906]\n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.906]        \n",
      "Epoch 684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.906]\n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.906]        \n",
      "Epoch 685: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.906]\n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=0.906]        \n",
      "Epoch 686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=0.906]\n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.906]        \n",
      "Epoch 687: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.906]\n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.906]        \n",
      "Epoch 688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.906]\n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.906]        \n",
      "Epoch 689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.906]\n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.906]        \n",
      "Epoch 690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.906]\n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.906]        \n",
      "Epoch 691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.906]\n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.906]        \n",
      "Epoch 692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.906]\n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.906]        \n",
      "Epoch 693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.906]\n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.906]        \n",
      "Epoch 694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.906]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.906]        \n",
      "Epoch 695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.906]\n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.906]        \n",
      "Epoch 696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.906]\n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.906]        \n",
      "Epoch 697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.906]\n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.906]        \n",
      "Epoch 698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.906]\n",
      "Epoch 698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.941, valid_loss=0.906]\n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.906]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.906]\n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.906]\n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.872, valid_loss=0.906]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.41it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]        \n",
      "Epoch 700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.941]        \n",
      "Epoch 701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.941]\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.941]        \n",
      "Epoch 702: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.941]\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]        \n",
      "Epoch 703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]\n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.941]        \n",
      "Epoch 704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.941]\n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.941]        \n",
      "Epoch 705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.941]\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.941]        \n",
      "Epoch 706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.941]\n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]        \n",
      "Epoch 707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]\n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]        \n",
      "Epoch 708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]\n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.941]        \n",
      "Epoch 709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.941]\n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]        \n",
      "Epoch 710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]\n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.941]        \n",
      "Epoch 711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.941]\n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.941]        \n",
      "Epoch 712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.941]\n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=0.941]        \n",
      "Epoch 713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=0.941]\n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.941]        \n",
      "Epoch 714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.941]\n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.941]        \n",
      "Epoch 715: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.941]\n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.941]        \n",
      "Epoch 716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.941]\n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.941]        \n",
      "Epoch 717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.941]\n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.941]        \n",
      "Epoch 718: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.941]\n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]        \n",
      "Epoch 719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]\n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.941]        \n",
      "Epoch 720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.941]\n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.941]        \n",
      "Epoch 721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.941]\n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]        \n",
      "Epoch 722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]\n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.941]        \n",
      "Epoch 723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.941]\n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.941]        \n",
      "Epoch 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.941]\n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.941]        \n",
      "Epoch 725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.941]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.941]        \n",
      "Epoch 726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.941]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.941]        \n",
      "Epoch 727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.941]\n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.941]        \n",
      "Epoch 728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.941]\n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]        \n",
      "Epoch 729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]\n",
      "Epoch 729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.941]\n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.941]        \n",
      "Epoch 730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.941]\n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=0.941]        \n",
      "Epoch 731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=0.941]\n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.941]        \n",
      "Epoch 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.941]\n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.941]        \n",
      "Epoch 733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.941]\n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858, valid_loss=0.941]        \n",
      "Epoch 734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858, valid_loss=0.941]\n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.941]        \n",
      "Epoch 735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.941]\n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.941]        \n",
      "Epoch 736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.941]\n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]        \n",
      "Epoch 737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]\n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.941]        \n",
      "Epoch 738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.941]\n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]        \n",
      "Epoch 739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]\n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.941]        \n",
      "Epoch 740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.941]\n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.941]        \n",
      "Epoch 741: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.941]\n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.941]        \n",
      "Epoch 742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.941]\n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.941]        \n",
      "Epoch 743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.941]\n",
      "Epoch 743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.941]\n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.941]        \n",
      "Epoch 744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.941]\n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.941]        \n",
      "Epoch 745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.941]\n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=0.941]        \n",
      "Epoch 746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=0.941]\n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.941]        \n",
      "Epoch 747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.941]\n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.941]        \n",
      "Epoch 748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.941]\n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]        \n",
      "Epoch 749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]\n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.941]        \n",
      "Epoch 750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.941]\n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.941]        \n",
      "Epoch 751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.941]\n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.941]        \n",
      "Epoch 752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.941]\n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.941]        \n",
      "Epoch 753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.941]\n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.941]        \n",
      "Epoch 754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.941]\n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]        \n",
      "Epoch 755: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]\n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.941]        \n",
      "Epoch 756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.941]\n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.941]        \n",
      "Epoch 757: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.941]\n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=0.941]        \n",
      "Epoch 758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=0.941]\n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.941]        \n",
      "Epoch 759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.941]\n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]        \n",
      "Epoch 760: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]\n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.941]        \n",
      "Epoch 761: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.941]\n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.941]        \n",
      "Epoch 762: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.941]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.941]        \n",
      "Epoch 763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.941]\n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.941]        \n",
      "Epoch 764: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.941]\n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]        \n",
      "Epoch 765: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.941]\n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.941]        \n",
      "Epoch 766: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.941]\n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.941]        \n",
      "Epoch 767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.941]\n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.941]        \n",
      "Epoch 768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.941]\n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.941]        \n",
      "Epoch 769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.941]\n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.941]        \n",
      "Epoch 770: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.941]\n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]        \n",
      "Epoch 771: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.941]\n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.941]        \n",
      "Epoch 772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.941]\n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.941]        \n",
      "Epoch 773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.941]\n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.941]        \n",
      "Epoch 774: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.941]\n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.941]        \n",
      "Epoch 775: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.941]\n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.941]        \n",
      "Epoch 776: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.941]\n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=0.941]        \n",
      "Epoch 777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=0.941]\n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.941]        \n",
      "Epoch 778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.941]\n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]        \n",
      "Epoch 779: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]\n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.941]        \n",
      "Epoch 780: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.941]\n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.941]        \n",
      "Epoch 781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.941]\n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.941]        \n",
      "Epoch 782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.941]\n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.941]        \n",
      "Epoch 783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.941]\n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.941]        \n",
      "Epoch 784: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.941]\n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.941]        \n",
      "Epoch 785: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.941]\n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.941]        \n",
      "Epoch 786: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.941]\n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=0.941]        \n",
      "Epoch 787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=0.941]\n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]        \n",
      "Epoch 788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]\n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]        \n",
      "Epoch 789: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.941]\n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]        \n",
      "Epoch 790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.941]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.941]        \n",
      "Epoch 791: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.941]\n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.941]        \n",
      "Epoch 792: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.941]\n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.941]        \n",
      "Epoch 793: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.941]\n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.941]        \n",
      "Epoch 794: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.941]\n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]        \n",
      "Epoch 795: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.941]\n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=0.941]        \n",
      "Epoch 796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890, valid_loss=0.941]\n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]        \n",
      "Epoch 797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.941]\n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.941]        \n",
      "Epoch 798: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.941]\n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.941]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.941]\n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=0.911, valid_loss=0.941]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.39it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.983]        \n",
      "Epoch 800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.983]\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=0.983]        \n",
      "Epoch 801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=0.983]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=0.983]        \n",
      "Epoch 802: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=0.983]\n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.983]        \n",
      "Epoch 803: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.983]\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.983]        \n",
      "Epoch 804: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.983]\n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.983]        \n",
      "Epoch 805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.983]\n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.983]        \n",
      "Epoch 806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.983]\n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.983]        \n",
      "Epoch 807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.983]\n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.983]        \n",
      "Epoch 808: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.983]\n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.983]        \n",
      "Epoch 809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.983]\n",
      "Epoch 809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.922, valid_loss=0.983]\n",
      "Epoch 809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.983]\n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.983]        \n",
      "Epoch 810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.983]\n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]        \n",
      "Epoch 811: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]\n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.983]        \n",
      "Epoch 812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.983]\n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.983]        \n",
      "Epoch 813: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.983]\n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.983]        \n",
      "Epoch 814: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.983]\n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.983]        \n",
      "Epoch 815: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.983]\n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.983]        \n",
      "Epoch 816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.983]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.983]        \n",
      "Epoch 817: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.983]\n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.983]        \n",
      "Epoch 818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.983]\n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.983]        \n",
      "Epoch 819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.983]\n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.983]        \n",
      "Epoch 820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.983]\n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.983]        \n",
      "Epoch 821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.983]\n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]        \n",
      "Epoch 822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]\n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.983]        \n",
      "Epoch 823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.983]\n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]        \n",
      "Epoch 824: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]\n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.983]        \n",
      "Epoch 825: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.983]\n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.983]        \n",
      "Epoch 826: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.983]\n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.983]        \n",
      "Epoch 827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.983]\n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.983]        \n",
      "Epoch 828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.983]\n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.983]        \n",
      "Epoch 829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.983]\n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.983]        \n",
      "Epoch 830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.983]\n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.983]        \n",
      "Epoch 831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.983]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.983]        \n",
      "Epoch 832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.983]\n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.983]        \n",
      "Epoch 833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.983]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.983]        \n",
      "Epoch 834: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.983]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.983]        \n",
      "Epoch 835: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.983]\n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.983]        \n",
      "Epoch 836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.983]\n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.983]        \n",
      "Epoch 837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.983]\n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]        \n",
      "Epoch 838: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.983]        \n",
      "Epoch 839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.983]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.983]        \n",
      "Epoch 840: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.983]\n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.983]        \n",
      "Epoch 841: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.983]\n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]        \n",
      "Epoch 842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.983]\n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.983]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.983]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=0.983]        \n",
      "Epoch 844: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=0.983]\n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.983]        \n",
      "Epoch 845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.983]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.983]        \n",
      "Epoch 846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.983]\n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.983]        \n",
      "Epoch 847: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.983]\n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.983]        \n",
      "Epoch 848: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.983]\n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.983]        \n",
      "Epoch 849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.983]\n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.983]        \n",
      "Epoch 850: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.983]\n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.983]        \n",
      "Epoch 851: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.983]\n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.983]        \n",
      "Epoch 852: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.983]\n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=0.983]        \n",
      "Epoch 853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=0.983]\n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.983]        \n",
      "Epoch 854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.983]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.983]        \n",
      "Epoch 855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.983]\n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.983]        \n",
      "Epoch 856: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.983]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.983]        \n",
      "Epoch 857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.983]\n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.983]        \n",
      "Epoch 858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.983]\n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.983]        \n",
      "Epoch 859: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.983]\n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.983]        \n",
      "Epoch 860: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.983]\n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.983]        \n",
      "Epoch 861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.983]\n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.983]        \n",
      "Epoch 862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.983]\n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.983]        \n",
      "Epoch 863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.983]\n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.983]        \n",
      "Epoch 864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.983]\n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.983]        \n",
      "Epoch 865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.983]\n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.983]        \n",
      "Epoch 866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.983]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.983]        \n",
      "Epoch 867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.983]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]        \n",
      "Epoch 868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.983]\n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.983]        \n",
      "Epoch 869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.983]\n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.983]        \n",
      "Epoch 870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.983]\n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.983]        \n",
      "Epoch 871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.983]\n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.983]        \n",
      "Epoch 872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.983]\n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.983]        \n",
      "Epoch 873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.983]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=0.983]        \n",
      "Epoch 874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=0.983]\n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.983]        \n",
      "Epoch 875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.983]\n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.983]        \n",
      "Epoch 876: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.983]\n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.983]        \n",
      "Epoch 877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.983]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.983]        \n",
      "Epoch 878: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.983]\n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.983]        \n",
      "Epoch 879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.983]\n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.983]        \n",
      "Epoch 880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.983]\n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.983]        \n",
      "Epoch 881: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.983]\n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.983]        \n",
      "Epoch 882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.983]\n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.983]        \n",
      "Epoch 883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=0.983]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.983]        \n",
      "Epoch 884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.983]\n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.983]        \n",
      "Epoch 885: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.983]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.983]        \n",
      "Epoch 886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.983]\n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.983]        \n",
      "Epoch 887: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.983]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.983]        \n",
      "Epoch 888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.983]\n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.983]        \n",
      "Epoch 889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.983]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.983]        \n",
      "Epoch 890: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.983]\n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.983]        \n",
      "Epoch 891: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.983]\n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.983]        \n",
      "Epoch 892: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.983]\n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.983]        \n",
      "Epoch 893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.983]\n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.983]        \n",
      "Epoch 894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.983]\n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.983]        \n",
      "Epoch 895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.983]\n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=0.983]        \n",
      "Epoch 896: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=0.983]\n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.983]        \n",
      "Epoch 897: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.983]\n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.983]        \n",
      "Epoch 898: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.983]\n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.983]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.983]\n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=0.958, valid_loss=0.983]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.30it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.050]        \n",
      "Epoch 900: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.050]\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=1.050]        \n",
      "Epoch 901: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=1.050]\n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=1.050]        \n",
      "Epoch 902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=1.050]\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.050]        \n",
      "Epoch 903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.050]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=1.050]        \n",
      "Epoch 904: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=1.050]\n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=1.050]        \n",
      "Epoch 905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=1.050]\n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=1.050]        \n",
      "Epoch 906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=1.050]\n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.050]        \n",
      "Epoch 907: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.050]\n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=1.050]        \n",
      "Epoch 908: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=1.050]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=1.050]        \n",
      "Epoch 909: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=1.050]\n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=1.050]        \n",
      "Epoch 910: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=1.050]\n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=1.050]        \n",
      "Epoch 911: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=1.050]\n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.050]        \n",
      "Epoch 912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.050]\n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.050]        \n",
      "Epoch 913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.050]\n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=1.050]        \n",
      "Epoch 914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=1.050]\n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=1.050]        \n",
      "Epoch 915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=1.050]\n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=1.050]        \n",
      "Epoch 916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=1.050]\n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858, valid_loss=1.050]        \n",
      "Epoch 917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858, valid_loss=1.050]\n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=1.050]        \n",
      "Epoch 918: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=1.050]\n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=1.050]        \n",
      "Epoch 919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=1.050]\n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=1.050]        \n",
      "Epoch 920: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=1.050]\n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=1.050]        \n",
      "Epoch 921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=1.050]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=1.050]        \n",
      "Epoch 922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=1.050]\n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=1.050]        \n",
      "Epoch 923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=1.050]\n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=1.050]        \n",
      "Epoch 924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=1.050]\n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=1.050]        \n",
      "Epoch 925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=1.050]\n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=1.050]        \n",
      "Epoch 926: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=1.050]\n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]        \n",
      "Epoch 927: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]\n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=1.050]        \n",
      "Epoch 928: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=1.050]\n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.050]        \n",
      "Epoch 929: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.050]\n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]        \n",
      "Epoch 930: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]\n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=1.050]        \n",
      "Epoch 931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=1.050]\n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=1.050]        \n",
      "Epoch 932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=1.050]\n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=1.050]        \n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.69it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=1.050]\n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.845, valid_loss=1.050]\n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=1.050]\n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=1.050]        \n",
      "Epoch 934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=1.050]\n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=1.050]        \n",
      "Epoch 935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=1.050]\n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=1.050]        \n",
      "Epoch 936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=1.050]\n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=1.050]        \n",
      "Epoch 937: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=1.050]\n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=1.050]        \n",
      "Epoch 938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=1.050]\n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=1.050]        \n",
      "Epoch 939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=1.050]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=1.050]        \n",
      "Epoch 940: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=1.050]\n",
      "Epoch 940: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]\n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]        \n",
      "Epoch 941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]\n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=0.843, valid_loss=1.050]        \n",
      "Epoch 942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=0.843, valid_loss=1.050]\n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=1.050]        \n",
      "Epoch 943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=1.050]\n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]        \n",
      "Epoch 944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]\n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=1.050]        \n",
      "Epoch 945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=1.050]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=1.050]        \n",
      "Epoch 946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=1.050]\n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=1.050]        \n",
      "Epoch 947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=1.050]\n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=1.050]        \n",
      "Epoch 948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=1.050]\n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=1.050]        \n",
      "Epoch 949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=1.050]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=1.050]        \n",
      "Epoch 950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=1.050]\n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.050]        \n",
      "Epoch 951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.050]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.050]        \n",
      "Epoch 952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.050]\n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=1.050]        \n",
      "Epoch 953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=1.050]\n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]        \n",
      "Epoch 954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.050]\n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.050]        \n",
      "Epoch 955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.050]\n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=1.050]        \n",
      "Epoch 956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=1.050]\n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=1.050]        \n",
      "Epoch 957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=1.050]\n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=1.050]        \n",
      "Epoch 958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=1.050]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=1.050]        \n",
      "Epoch 959: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=1.050]\n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=1.050]        \n",
      "Epoch 960: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=1.050]\n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.050]        \n",
      "Epoch 961: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.050]\n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=1.050]        \n",
      "Epoch 962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=1.050]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=1.050]        \n",
      "Epoch 963: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=1.050]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=1.050]        \n",
      "Epoch 964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=1.050]\n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=1.050]        \n",
      "Epoch 965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=1.050]\n",
      "Epoch 965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.873, valid_loss=1.050]\n",
      "Epoch 965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]\n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]        \n",
      "Epoch 966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.050]\n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=1.050]        \n",
      "Epoch 967: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=1.050]\n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.050]        \n",
      "Epoch 968: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.050]\n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.050]        \n",
      "Epoch 969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.050]\n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=1.050]        \n",
      "Epoch 970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=1.050]\n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=1.050]        \n",
      "Epoch 971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=1.050]\n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=1.050]        \n",
      "Epoch 972: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=1.050]\n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=1.050]        \n",
      "Epoch 973: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=1.050]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=1.050]        \n",
      "Epoch 974: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=1.050]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=1.050]        \n",
      "Epoch 975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=1.050]\n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=1.050]        \n",
      "Epoch 976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.40it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=1.050]\n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=1.050]        \n",
      "Epoch 977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=1.050]\n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=1.050]        \n",
      "Epoch 978: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=1.050]\n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=1.050]        \n",
      "Epoch 979: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=1.050]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=1.050]        \n",
      "Epoch 980: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=1.050]\n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=1.050]        \n",
      "Epoch 981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=1.050]\n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=1.050]        \n",
      "Epoch 982: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=1.050]\n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=1.050]        \n",
      "Epoch 983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=1.050]\n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=1.050]        \n",
      "Epoch 984: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=1.050]\n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=1.050]        \n",
      "Epoch 985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=1.050]\n",
      "Epoch 985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=1.050]\n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=1.050]        \n",
      "Epoch 986: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=1.050]\n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=1.050]        \n",
      "Epoch 987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=1.050]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=1.050]        \n",
      "Epoch 988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=1.050]\n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=1.050]        \n",
      "Epoch 989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=1.050]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=1.050]        \n",
      "Epoch 990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=1.050]\n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=1.050]        \n",
      "Epoch 991: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=1.050]\n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=1.050]        \n",
      "Epoch 992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.53it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=1.050]\n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=1.050]        \n",
      "Epoch 993: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=1.050]\n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=1.050]        \n",
      "Epoch 994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=1.050]\n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=1.050]        \n",
      "Epoch 995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.49it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=1.050]\n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=1.050]        \n",
      "Epoch 996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=1.050]\n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=1.050]        \n",
      "Epoch 997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=1.050]\n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=1.050]        \n",
      "Epoch 998: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=1.050]\n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=1.050]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=1.050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 04:03:54,733\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.825, valid_loss=1.050]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.83it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.52it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=1.080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=17572)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]        \n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]        \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.79it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]       \n",
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.01it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.06it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.07it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]        \n",
      "Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]\n",
      "Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948]        \n",
      "Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948]\n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965]        \n",
      "Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]        \n",
      "Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]        \n",
      "Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.62it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.46it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.030]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.86it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]       \n",
      "Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.856]        \n",
      "Epoch 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.856]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.856]        \n",
      "Epoch 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.856]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.856]        \n",
      "Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.856]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]        \n",
      "Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]\n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]        \n",
      "Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]        \n",
      "Epoch 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]\n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.856]        \n",
      "Epoch 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.856]\n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]        \n",
      "Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]        \n",
      "Epoch 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]\n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]        \n",
      "Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]\n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]        \n",
      "Epoch 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.856]        \n",
      "Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.856]\n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.856]        \n",
      "Epoch 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.856]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]        \n",
      "Epoch 117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]\n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.856]        \n",
      "Epoch 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.856]\n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.856]        \n",
      "Epoch 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.856]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]        \n",
      "Epoch 120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.856]        \n",
      "Epoch 121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.856]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]        \n",
      "Epoch 122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]\n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]        \n",
      "Epoch 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]\n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.856]        \n",
      "Epoch 124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.856]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]        \n",
      "Epoch 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]\n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.856]        \n",
      "Epoch 128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.856]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.856]        \n",
      "Epoch 129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.856]\n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=0.856]        \n",
      "Epoch 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=0.856]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]        \n",
      "Epoch 131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]\n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]        \n",
      "Epoch 132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]\n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]        \n",
      "Epoch 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]        \n",
      "Epoch 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]\n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.856]        \n",
      "Epoch 136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.856]\n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]        \n",
      "Epoch 137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]        \n",
      "Epoch 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]        \n",
      "Epoch 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 140: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]        \n",
      "Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]\n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]        \n",
      "Epoch 144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.856]        \n",
      "Epoch 145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.856]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]        \n",
      "Epoch 146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]\n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]        \n",
      "Epoch 147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]        \n",
      "Epoch 148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.92it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.856]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.856]        \n",
      "Epoch 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.856]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]        \n",
      "Epoch 151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]\n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.856]        \n",
      "Epoch 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.856]\n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.856]        \n",
      "Epoch 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.856]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=0.856]        \n",
      "Epoch 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=0.856]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.856]        \n",
      "Epoch 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.856]\n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.856]        \n",
      "Epoch 159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.856]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.856]        \n",
      "Epoch 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.856]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]        \n",
      "Epoch 163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.71it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]        \n",
      "Epoch 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]        \n",
      "Epoch 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.856]        \n",
      "Epoch 167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.856]\n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.856]        \n",
      "Epoch 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.856]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.856]        \n",
      "Epoch 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.856]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]        \n",
      "Epoch 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]        \n",
      "Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.856]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.856]        \n",
      "Epoch 174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.856]\n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]        \n",
      "Epoch 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.856]\n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]        \n",
      "Epoch 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.856]\n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]        \n",
      "Epoch 177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]\n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.856]        \n",
      "Epoch 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.856]\n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.856]        \n",
      "Epoch 179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.856]\n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]        \n",
      "Epoch 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.856]        \n",
      "Epoch 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.856]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]        \n",
      "Epoch 183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.856]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]        \n",
      "Epoch 184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.856]\n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]        \n",
      "Epoch 185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]        \n",
      "Epoch 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.856]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]        \n",
      "Epoch 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.856]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]        \n",
      "Epoch 189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.856]\n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.856]        \n",
      "Epoch 190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.856]\n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]        \n",
      "Epoch 192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.856]\n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.856]        \n",
      "Epoch 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.856]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.856]        \n",
      "Epoch 194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.856]\n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.856]        \n",
      "Epoch 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.856]\n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]        \n",
      "Epoch 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.856]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]        \n",
      "Epoch 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.856]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]        \n",
      "Epoch 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.856]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.856]\n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.62it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=0.856]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.60it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]        \n",
      "Epoch 203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.41it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.863]        \n",
      "Epoch 204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=0.863]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]        \n",
      "Epoch 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.863]        \n",
      "Epoch 206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.863]\n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]        \n",
      "Epoch 211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]\n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]        \n",
      "Epoch 215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.06it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]        \n",
      "Epoch 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]        \n",
      "Epoch 221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]        \n",
      "Epoch 223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]\n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]        \n",
      "Epoch 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]        \n",
      "Epoch 226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.863]        \n",
      "Epoch 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.863]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.02it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]        \n",
      "Epoch 230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.46it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.863]        \n",
      "Epoch 235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.863]\n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.863]        \n",
      "Epoch 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.863]\n",
      "Epoch 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.863]        \n",
      "Epoch 242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.863]\n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.98it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]        \n",
      "Epoch 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]        \n",
      "Epoch 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.97it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.863]        \n",
      "Epoch 250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.78it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.863]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.863]        \n",
      "Epoch 251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.863]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]        \n",
      "Epoch 254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]\n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.863]        \n",
      "Epoch 255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.863]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.863]        \n",
      "Epoch 256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.863]\n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.863]        \n",
      "Epoch 258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.863]\n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]        \n",
      "Epoch 263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]\n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 265: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.863]        \n",
      "Epoch 266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.863]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]        \n",
      "Epoch 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.863]        \n",
      "Epoch 268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.863]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]        \n",
      "Epoch 271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]        \n",
      "Epoch 274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]\n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]        \n",
      "Epoch 276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.863]        \n",
      "Epoch 278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.863]\n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.863]        \n",
      "Epoch 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.863]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.863]        \n",
      "Epoch 280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.863]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.863]        \n",
      "Epoch 281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.863]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]        \n",
      "Epoch 282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.863]\n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.863]        \n",
      "Epoch 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.863]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.863]        \n",
      "Epoch 288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=0.863]\n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]        \n",
      "Epoch 289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]        \n",
      "Epoch 290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]\n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]        \n",
      "Epoch 291: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.863]        \n",
      "Epoch 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.863]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.863]        \n",
      "Epoch 294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.863]\n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.863]        \n",
      "Epoch 296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.863]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]        \n",
      "Epoch 298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.863]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.863]\n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.958, valid_loss=0.863]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.86it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.863]        \n",
      "Epoch 300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.863]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]        \n",
      "Epoch 302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]        \n",
      "Epoch 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]        \n",
      "Epoch 304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]        \n",
      "Epoch 305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]\n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.863]        \n",
      "Epoch 307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.863]\n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]        \n",
      "Epoch 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]\n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]        \n",
      "Epoch 309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]        \n",
      "Epoch 310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]\n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.863]        \n",
      "Epoch 313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.863]\n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.863]        \n",
      "Epoch 314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.863]\n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]        \n",
      "Epoch 316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.863]\n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]        \n",
      "Epoch 317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.863]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 319: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]        \n",
      "Epoch 320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]        \n",
      "Epoch 321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]\n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.863]        \n",
      "Epoch 322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.863]\n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.863]        \n",
      "Epoch 324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.863]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.863]        \n",
      "Epoch 327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.863]\n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]        \n",
      "Epoch 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]\n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]        \n",
      "Epoch 331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]        \n",
      "Epoch 333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.02it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]\n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.863]        \n",
      "Epoch 334: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.863]\n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.863]        \n",
      "Epoch 336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.863]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]        \n",
      "Epoch 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.863]\n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.863]        \n",
      "Epoch 340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.863]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]        \n",
      "Epoch 341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]\n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 343: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]        \n",
      "Epoch 344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]\n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.863]        \n",
      "Epoch 346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.863]\n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.863]        \n",
      "Epoch 347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.863]\n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]        \n",
      "Epoch 348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.863]\n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]        \n",
      "Epoch 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.863]        \n",
      "Epoch 354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.863]\n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.863]        \n",
      "Epoch 357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.863]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]        \n",
      "Epoch 358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.863]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 360: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]        \n",
      "Epoch 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.863]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.863]        \n",
      "Epoch 362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.863]\n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.863]        \n",
      "Epoch 364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.863]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.863]        \n",
      "Epoch 365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.863]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]        \n",
      "Epoch 366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.863]\n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]        \n",
      "Epoch 367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.863]\n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.863]        \n",
      "Epoch 369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.863]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]        \n",
      "Epoch 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.863]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.863]        \n",
      "Epoch 373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.863]\n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]        \n",
      "Epoch 374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]        \n",
      "Epoch 375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.863]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]        \n",
      "Epoch 376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.863]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.863]        \n",
      "Epoch 377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.863]\n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.863]        \n",
      "Epoch 378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.863]\n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.863]        \n",
      "Epoch 380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.863]\n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.863]        \n",
      "Epoch 381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.863]\n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]        \n",
      "Epoch 382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.863]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]        \n",
      "Epoch 383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.863]\n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]        \n",
      "Epoch 384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.863]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]        \n",
      "Epoch 385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.863]        \n",
      "Epoch 387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.863]\n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]        \n",
      "Epoch 389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.863]\n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]        \n",
      "Epoch 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.863]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.863]        \n",
      "Epoch 391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.863]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]        \n",
      "Epoch 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.110, valid_loss=0.863]\n",
      "Epoch 392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]        \n",
      "Epoch 393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.863]\n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]        \n",
      "Epoch 394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.863]\n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]        \n",
      "Epoch 395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.863]\n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]        \n",
      "Epoch 396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.863]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]        \n",
      "Epoch 397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.863]\n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.863]        \n",
      "Epoch 398: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.863]\n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.863]\n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.62it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.150, valid_loss=0.863]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.13it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.869]        \n",
      "Epoch 400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.869]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]        \n",
      "Epoch 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]\n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.96it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]        \n",
      "Epoch 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.869]        \n",
      "Epoch 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.869]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]        \n",
      "Epoch 407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]\n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.869]        \n",
      "Epoch 408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.869]\n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 409: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]        \n",
      "Epoch 410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]\n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.869]        \n",
      "Epoch 412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.869]\n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]        \n",
      "Epoch 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.07it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.869]        \n",
      "Epoch 414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.869]\n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.869]        \n",
      "Epoch 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.869]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]        \n",
      "Epoch 416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]\n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.869]        \n",
      "Epoch 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.869]\n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.869]        \n",
      "Epoch 418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.869]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]        \n",
      "Epoch 419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]\n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.869]        \n",
      "Epoch 420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.869]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]        \n",
      "Epoch 421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]\n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]        \n",
      "Epoch 424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.869]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.869]        \n",
      "Epoch 426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.869]\n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.869]        \n",
      "Epoch 427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.869]\n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.869]        \n",
      "Epoch 428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.869]\n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.869]        \n",
      "Epoch 429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.869]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.869]        \n",
      "Epoch 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.869]\n",
      "Epoch 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=0.964, valid_loss=0.869]\n",
      "Epoch 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]        \n",
      "Epoch 432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.869]        \n",
      "Epoch 433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.869]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]        \n",
      "Epoch 434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]\n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]        \n",
      "Epoch 435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]\n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.869]        \n",
      "Epoch 436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.869]\n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.869]        \n",
      "Epoch 438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.869]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.869]        \n",
      "Epoch 440: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.85it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.869]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.869]        \n",
      "Epoch 441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.869]\n",
      "Epoch 441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.70it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.869]\n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.869]        \n",
      "Epoch 442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.03it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.869]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.869]        \n",
      "Epoch 445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.869]\n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]        \n",
      "Epoch 446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.869]        \n",
      "Epoch 447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.869]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.869]        \n",
      "Epoch 448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.869]\n",
      "Epoch 448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.63it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.869]\n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.869]        \n",
      "Epoch 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.869]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]        \n",
      "Epoch 450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]\n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.869]        \n",
      "Epoch 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.869]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.869]        \n",
      "Epoch 452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.869]\n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]        \n",
      "Epoch 453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]\n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.869]        \n",
      "Epoch 454: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.869]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.869]        \n",
      "Epoch 455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.869]\n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.869]        \n",
      "Epoch 456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.869]\n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.869]        \n",
      "Epoch 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.869]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]        \n",
      "Epoch 458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.869]        \n",
      "Epoch 459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.869]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.869]        \n",
      "Epoch 460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.91it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.869]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.869]        \n",
      "Epoch 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.95it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.869]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.869]        \n",
      "Epoch 463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.869]\n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.869]        \n",
      "Epoch 464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.869]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.869]        \n",
      "Epoch 465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.92it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.869]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.869]        \n",
      "Epoch 466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.869]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.869]        \n",
      "Epoch 467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.869]\n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.869]        \n",
      "Epoch 468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.869]\n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.869]        \n",
      "Epoch 471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.869]\n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.869]        \n",
      "Epoch 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.869]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.869]        \n",
      "Epoch 473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.869]\n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.869]        \n",
      "Epoch 474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.869]\n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]        \n",
      "Epoch 475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.869]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]        \n",
      "Epoch 476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]\n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.869]        \n",
      "Epoch 477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.869]\n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.869]        \n",
      "Epoch 478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.869]\n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]        \n",
      "Epoch 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.869]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]        \n",
      "Epoch 481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]\n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.869]        \n",
      "Epoch 483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.869]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]        \n",
      "Epoch 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.869]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.869]        \n",
      "Epoch 485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.869]\n",
      "Epoch 485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.65it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]\n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]        \n",
      "Epoch 486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.869]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]        \n",
      "Epoch 488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.869]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]        \n",
      "Epoch 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.869]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.869]        \n",
      "Epoch 490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.869]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.869]        \n",
      "Epoch 491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.869]\n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]        \n",
      "Epoch 492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.869]        \n",
      "Epoch 493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.869]\n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.869]        \n",
      "Epoch 494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.869]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]        \n",
      "Epoch 495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.869]\n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.869]        \n",
      "Epoch 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.869]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]        \n",
      "Epoch 498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.869]\n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.030, valid_loss=0.869]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=17572)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.49it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.872]        \n",
      "Epoch 500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.872]\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.872]        \n",
      "Epoch 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.872]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]        \n",
      "Epoch 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.872]        \n",
      "Epoch 503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.872]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]        \n",
      "Epoch 505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.872]        \n",
      "Epoch 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.872]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.872]        \n",
      "Epoch 507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.872]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]        \n",
      "Epoch 508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]\n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.872]        \n",
      "Epoch 509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.872]\n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.872]        \n",
      "Epoch 510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.872]\n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.872]        \n",
      "Epoch 511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.872]\n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.872]        \n",
      "Epoch 512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.872]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.872]        \n",
      "Epoch 513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.872]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.872]        \n",
      "Epoch 514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.39it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.872]\n",
      "Epoch 514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.67it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.872]\n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.872]        \n",
      "Epoch 515: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.872]\n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.872]        \n",
      "Epoch 516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.872]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.872]        \n",
      "Epoch 517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.872]\n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.872]        \n",
      "Epoch 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.872]\n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.872]        \n",
      "Epoch 519: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.872]\n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]        \n",
      "Epoch 520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.872]        \n",
      "Epoch 521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.872]\n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.872]        \n",
      "Epoch 522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.872]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]        \n",
      "Epoch 523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]\n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]        \n",
      "Epoch 525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.42it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]\n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.872]        \n",
      "Epoch 526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.872]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.872]        \n",
      "Epoch 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.872]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.872]        \n",
      "Epoch 528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.872]\n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.872]        \n",
      "Epoch 529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.36it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.872]\n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]        \n",
      "Epoch 530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]\n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]        \n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.25it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.872]        \n",
      "Epoch 532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.872]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.872]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.872]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.872]        \n",
      "Epoch 534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.872]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=0.872]        \n",
      "Epoch 535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=0.872]\n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]        \n",
      "Epoch 538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.872]        \n",
      "Epoch 539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.872]\n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.872]        \n",
      "Epoch 541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.872]\n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.872]        \n",
      "Epoch 542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.872]\n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]        \n",
      "Epoch 543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]\n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]        \n",
      "Epoch 544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.872]\n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]        \n",
      "Epoch 545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]\n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.872]        \n",
      "Epoch 546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.872]\n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.872]        \n",
      "Epoch 547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.872]\n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.872]        \n",
      "Epoch 548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.872]\n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.872]        \n",
      "Epoch 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.872]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.872]        \n",
      "Epoch 550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.872]\n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.872]        \n",
      "Epoch 551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.872]\n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]        \n",
      "Epoch 552: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]\n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.872]        \n",
      "Epoch 554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.872]\n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.872]        \n",
      "Epoch 555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.872]\n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.872]        \n",
      "Epoch 556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.872]\n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.872]        \n",
      "Epoch 557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.872]\n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.872]        \n",
      "Epoch 558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.872]\n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.872]        \n",
      "Epoch 560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.872]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.872]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.872]        \n",
      "Epoch 562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.872]\n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.872]        \n",
      "Epoch 563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.872]\n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.872]        \n",
      "Epoch 564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.872]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.872]        \n",
      "Epoch 565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.872]\n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.872]        \n",
      "Epoch 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.872]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.872]        \n",
      "Epoch 567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.872]\n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.872]        \n",
      "Epoch 568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.872]\n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.872]        \n",
      "Epoch 569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.872]\n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.872]        \n",
      "Epoch 571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.872]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.872]        \n",
      "Epoch 573: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.872]\n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.872]        \n",
      "Epoch 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.872]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.872]        \n",
      "Epoch 575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.13it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.872]\n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.872]        \n",
      "Epoch 576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.872]\n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.30it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.872]        \n",
      "Epoch 579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.46it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.872]\n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.872]        \n",
      "Epoch 581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.872]\n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.872]        \n",
      "Epoch 582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.872]\n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]        \n",
      "Epoch 583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.872]\n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.872]        \n",
      "Epoch 584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.872]\n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.872]        \n",
      "Epoch 585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.872]\n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]        \n",
      "Epoch 586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.872]\n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.872]        \n",
      "Epoch 587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.872]\n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.872]        \n",
      "Epoch 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.872]\n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.872]        \n",
      "Epoch 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.872]\n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.872]        \n",
      "Epoch 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=0.872]\n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]        \n",
      "Epoch 592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.872]\n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.872]        \n",
      "Epoch 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.872]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]        \n",
      "Epoch 594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.872]\n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.872]        \n",
      "Epoch 595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.872]\n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.872]        \n",
      "Epoch 596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.00it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.872]\n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]        \n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.872]\n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.872]        \n",
      "Epoch 598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.872]\n"
     ]
    }
   ],
   "source": [
    "models = [AutoRNN(h=1, config=config_rnn, loss=MSE(), num_samples=32, search_alg=HyperOptSearch()),\n",
    "          AutoVanillaTransformer(h=1, config=config_transformers, loss=MSE(), num_samples=32, search_alg=HyperOptSearch()),\n",
    "          AutoAutoformer(h=1, config=config_autoformer, loss=MSE(), num_samples=32, search_alg=HyperOptSearch())]\n",
    "\n",
    "nf = NeuralForecast(models=models, \n",
    "                    freq=\"D\", \n",
    "                    local_scaler_type=\"standard\")\n",
    "pred = nf.cross_validation(df=df_lst[-1],  # PSEI.PS Log Returns\n",
    "                           val_size=val_size,\n",
    "                           test_size=365,\n",
    "                          n_windows=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fc3da852748743f5b47d9f6d441e7c4f",
      "62ae02005bbd4c3dbd6a06d7638c995b",
      "7f100ae6e1b0431d9a8039a2a3238dd6",
      "f8a8d5e1d90a497baa2deae00428446d",
      "11e6983ab6314dd4b19d73f71b09939b",
      "49b32944b0584896ac3f1a68b5375e6d",
      "81addce944d74d939e1428a9ce6c70e4",
      "a35c4a40764b4e6bb8fdc73b055df236",
      "69ac1b7b2abb4e398f7c38a1be7b6e77",
      "697dee2cfdfc4017bcedbe22c2ee23a2",
      "d2a808d3c2cd49409113c9337c421b8f"
     ]
    },
    "id": "Lj4NNSUw2r49",
    "outputId": "9df1a9bb-31cd-40a2-d9c2-84a36551f33c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred2 = nf.predict_insample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5PJ82xAJHSDm",
    "outputId": "505a1670-3d43-4b93-f9ce-916518ec95e6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "o0vD_zziXzGd",
    "outputId": "915601aa-af4a-4c3c-e163-70fa933c7a75"
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "YXc38_JG58DL",
    "outputId": "ca199c6d-afcf-4594-de0e-8de3ca5fd77b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true_2 = pred2['y'].values\n",
    "y_transformer_2 = pred2['VanillaTransformer'].values\n",
    "y_rnn_2 = pred2['RNN'].values\n",
    "\n",
    "n_series = len(pred2['unique_id'].unique())\n",
    "y_true_2 = y_true_2.reshape(n_series, -1, horizon)\n",
    "y_transformer_2 = y_transformer_2.reshape(n_series, -1, horizon)\n",
    "y_rnn_2 = y_rnn_2.reshape(n_series, -1, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIcNGYEP364t"
   },
   "outputs": [],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = nf.models[0].results.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SzMyaZMe3oN7",
    "outputId": "b26367c1-d28c-4d5e-e8fc-1614b6661536",
    "tags": []
   },
   "outputs": [],
   "source": [
    "hello2 = pred2.groupby(['ds'])[\n",
    "    [\"y\",\n",
    "     \"AutoRNN\",\n",
    "     \"AutoVanillaTransformer\",\n",
    "     \"AutoAutoformer\"\n",
    "     ]\n",
    "].mean()\n",
    "\n",
    "for i in range(2010,2017):\n",
    "  plt.figure(figsize=(15,3))\n",
    "  plt.plot(hello2.loc[f\"{i}-01-01\":f\"{i+1}-01-01\":], linewidth=0.75)\n",
    "  plt.legend([\"True\", \"RNN\", \"Transformer\", \"Autoformer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8WMu5jyyrgd"
   },
   "outputs": [],
   "source": [
    "nf.save(path=\"/content/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swSErUkMuERR"
   },
   "outputs": [],
   "source": [
    "y_true = pred['y'].values\n",
    "y_transformer = pred['VanillaTransformer'].values\n",
    "y_rnn = pred['RNN'].values\n",
    "\n",
    "n_series = len(pred['unique_id'].unique())\n",
    "y_true = y_true.reshape(n_series, -1, horizon)\n",
    "y_transformer = y_transformer.reshape(n_series, -1, horizon)\n",
    "y_rnn = y_rnn.reshape(n_series, -1, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zztUZL4RwJ6Z"
   },
   "outputs": [],
   "source": [
    "y_transformer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLarMIpF6ux9"
   },
   "outputs": [],
   "source": [
    "from neuralforecast.losses.numpy import mae, mse, mape, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDbcHbhr3jhq"
   },
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "print(f\"Transformer: MSE: {mse(y_true_2, y_transformer_2)}, MAE: {mae(y_true_2, y_transformer_2)}, MAPE: {mape(y_true_2, y_transformer_2)}, RMSE: {rmse(y_true_2, y_transformer_2)}\")\n",
    "print(f\"RNN: MSE: {mse(y_true_2, y_rnn_2)}, MAE: {mae(y_true_2, y_rnn_2)}, MAPE: {mape(y_true_2, y_rnn_2)}, RMSE: {rmse(y_true_2, y_rnn_2)}\")\n",
    "print(\"Test\")\n",
    "print(f\"Transformer: MSE: {mse(y_true, y_transformer)}, MAE: {mae(y_true, y_transformer)}, MAPE: {mape(y_true, y_transformer)}, RMSE: {rmse(y_true, y_transformer)}\")\n",
    "print(f\"RNN: MSE: {mse(y_true, y_rnn)}, MAE: {mae(y_true, y_rnn)}, MAPE: {mape(y_true, y_rnn)}, RMSE: {rmse(y_true, y_rnn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "iFfFuKt0zfDL",
    "outputId": "4265dc60-743e-42a2-ce83-bb953a3509e3"
   },
   "outputs": [],
   "source": [
    "hello = pred.groupby(['ds'])[['y','VanillaTransformer','VanillaTransformer1','VanillaTransformer2','VanillaTransformer3','VanillaTransformer4']].mean()\n",
    "for i in range(2018,2020):\n",
    "  plt.figure(figsize=(15,3))\n",
    "  plt.plot(hello.loc[f\"{i}-01-01\":f\"{i+1}-01-01\":], linewidth=0.75)\n",
    "  plt.legend(['True', 'Dropout 0', 'Dropout 0.1', 'Dropout 0.2', 'Dropout 0.3', 'Dropout 0.4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIWbrUJ5v62n"
   },
   "outputs": [],
   "source": [
    "\n",
    "series = ['PSEI']\n",
    "series_idx = 3\n",
    "\n",
    "for w_idx in enumerate([200, 300, 400]):\n",
    "  plt.figure()\n",
    "  plt.plot(y_true[0, w_idx,:].flatten(),label='True',color=\"r\")\n",
    "  plt.plot(y_transformer[0, w_idx,:].flatten(), label='VanillaTransformer', color=\"g\")\n",
    "  plt.plot(y_rnn[0, w_idx,:].flatten(),label='RNN', color=\"b\")\n",
    "  plt.grid()\n",
    "  if idx==2:\n",
    "    plt.set_xlabel('Forecast Horizon', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTKyFmUTLk9y"
   },
   "outputs": [],
   "source": [
    "hello = pred.groupby(['cutoff'])[['y','VanillaTransformer','RNN']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUQ87p5hWS5I"
   },
   "outputs": [],
   "source": [
    "hello['ds'] = hello.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCHJuSn4v6Zr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND-7-tnsKR_J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,4), linewidth=1)\n",
    "plt.plot(hello['ds'],hello['y'], label='true')\n",
    "plt.plot(hello['ds'],hello['VanillaTransformer'], label='Transformer')\n",
    "plt.plot(hello['ds'],hello['RNN'], label='RNN')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11e6983ab6314dd4b19d73f71b09939b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "33a2d42468714c0998d3b0a63dec123a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49b32944b0584896ac3f1a68b5375e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4aa6091d14fe48af8b090ee16666b74a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e2dd7aac6d842dcb987d5417b1b5487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac2eb6bedd8f4bff807a58175bad5e0b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f10cd5d8f6ca4266bf08eb05b3c5940a",
      "value": "Sanity Checking DataLoader 0:   0%"
     }
    },
    "62ae02005bbd4c3dbd6a06d7638c995b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b32944b0584896ac3f1a68b5375e6d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_81addce944d74d939e1428a9ce6c70e4",
      "value": "Predicting DataLoader 0: 100%"
     }
    },
    "659fef089ee247e599e6fcdde8eddfaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33a2d42468714c0998d3b0a63dec123a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b64305d4a1d84703b856327b96f83084",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "697dee2cfdfc4017bcedbe22c2ee23a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69ac1b7b2abb4e398f7c38a1be7b6e77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f100ae6e1b0431d9a8039a2a3238dd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a35c4a40764b4e6bb8fdc73b055df236",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69ac1b7b2abb4e398f7c38a1be7b6e77",
      "value": 1
     }
    },
    "81addce944d74d939e1428a9ce6c70e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a35c4a40764b4e6bb8fdc73b055df236": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac2eb6bedd8f4bff807a58175bad5e0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b11e473f57d044b48760707574611afb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e2dd7aac6d842dcb987d5417b1b5487",
       "IPY_MODEL_c388f95c4c4d4b9ab5cdf1da5cff808a",
       "IPY_MODEL_659fef089ee247e599e6fcdde8eddfaf"
      ],
      "layout": "IPY_MODEL_cd47a1711d0047e8a406b464b3a4ad8f"
     }
    },
    "b64305d4a1d84703b856327b96f83084": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bac194cb12924ecb85d52b82c27b315b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c388f95c4c4d4b9ab5cdf1da5cff808a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aa6091d14fe48af8b090ee16666b74a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bac194cb12924ecb85d52b82c27b315b",
      "value": 0
     }
    },
    "cd47a1711d0047e8a406b464b3a4ad8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "d2a808d3c2cd49409113c9337c421b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f10cd5d8f6ca4266bf08eb05b3c5940a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8a8d5e1d90a497baa2deae00428446d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_697dee2cfdfc4017bcedbe22c2ee23a2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d2a808d3c2cd49409113c9337c421b8f",
      "value": " 1/1 [00:17&lt;00:00,  0.06it/s]"
     }
    },
    "fc3da852748743f5b47d9f6d441e7c4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62ae02005bbd4c3dbd6a06d7638c995b",
       "IPY_MODEL_7f100ae6e1b0431d9a8039a2a3238dd6",
       "IPY_MODEL_f8a8d5e1d90a497baa2deae00428446d"
      ],
      "layout": "IPY_MODEL_11e6983ab6314dd4b19d73f71b09939b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
